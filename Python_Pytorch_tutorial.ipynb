{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python与Pytorch教程"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python基础\n",
    "\n",
    "- Python基础数据类型：整型、浮点型、字符串、布尔型、列表、元组、字典、集合\n",
    "- Python基础语法：条件语句、循环语句、函数、类\n",
    "- Numpy基础：数组、矩阵、线性代数、随机数\n",
    "- Matplotlib基础：绘图、子图、图例、坐标轴、文本、注释\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Python基础数据类型\n",
    "#### 整数和浮点数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x + 2) # Addition\n",
    "print(x - 2) # Subtraction\n",
    "print(x * 4) # Multiplication\n",
    "print(x ** 4) # Exponentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x += 2\n",
    "print(x)\n",
    "x *= 2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 3.5\n",
    "print(type(y)) # Prints \"<class 'float'>\"\n",
    "print(y, y + 1, y * 2, y ** 2) # Prints \"3.5 4.5 7.0 12.25\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 布尔型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, f = True, False\n",
    "print(type(t)) # Prints \"<class 'bool'>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t and f) # Logical AND; prints \"False\"\n",
    "print(t or f) # Logical OR; prints \"True\"\n",
    "print(not t) # Logical NOT; prints \"False\"\n",
    "print(t != f) # Logical XOR; prints \"True\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_word = '2023'\n",
    "second_word = 'AI训练营'\n",
    "print(first_word, len(first_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_words = first_word + ' ' + second_word\n",
    "print(two_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_words_format = '{} {} {}'.format(first_word, second_word, 2)\n",
    "print(two_words_format)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 字符串方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'hello'\n",
    "print(w.capitalize()) # Capitalize a string; prints \"Hello\"\n",
    "print(w.upper()) # Convert a string to uppercase; prints \"HELLO\"\n",
    "print(w.rjust(7)) # Right-justify a string, padding with spaces; prints \" hello\"\n",
    "print(w.center(7)) # Center a string, padding with spaces; prints \" hello \"\n",
    "print(w.replace('l', '(ell)')) # Replace all instances of one substring with another;\n",
    "print(' world '.strip()) # Strip leading and trailing whitespace; prints \"world\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [5,2,3,4,1] # Create a list\n",
    "print(ls, ls[2]) # Prints \"[5, 2, 3, 4, 1] 3\"\n",
    "print(ls[-1]) # Negative indices count from the end of the list; prints \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls[2] = 'university' # Lists can contain elements of different types\n",
    "print(ls) # Prints \"[5, 2, 'university', 4, 1]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.append('AI') # Add a new element to the end of the list\n",
    "print(ls) # Prints \"[5, 2, 'university', 4, 1, 'AI']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ls.pop() # Remove and return the last element of the list\n",
    "print(a, ls) # Prints \"AI [5, 2, 'university', 4, 1]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 列表切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = list(range(7)) # range is a built-in function that creates a list of integers\n",
    "print(nums) # Prints \"[0, 1, 2, 3, 4, 5, 6]\"\n",
    "print(nums[2:4]) # Get a slice from index 2 to 4 (exclusive); prints \"[2, 3]\"\n",
    "print(nums[2:]) # Get a slice from index 2 to the end; prints \"[2, 3, 4, 5, 6]\"\n",
    "print(nums[:2]) # Get a slice from the start to index 2 (exclusive); prints \"[0, 1]\"\n",
    "print(nums[:]) # Get a slice of the whole list; prints \"[0, 1, 2, 3, 4, 5, 6]\"\n",
    "print(nums[:-1]) # Slice indices can be negative; prints \"[0, 1, 2, 3, 4, 5]\"\n",
    "nums[2:4] = [8, 9] # Assign a new sublist to a slice\n",
    "print(nums) # Prints \"[0, 1, 8, 9, 4, 5, 6]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_concepts = ['AI', 'Deep Learning', 'Machine Learning', 'Neural Network']\n",
    "for concept in AI_concepts:\n",
    "    print(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_concepts = ['AI', 'Deep Learning', 'Machine Learning', 'Neural Network']\n",
    "for i, concept in enumerate(AI_concepts):\n",
    "    print('#%d: %s' % (i + 1, concept))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 列表推导式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0, 1, 2, 3, 4]\n",
    "squares = []\n",
    "for x in nums:\n",
    "    squares.append(x ** 2)\n",
    "print(squares) # Prints \"[0, 1, 4, 9, 16]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0, 1, 2, 3, 4]\n",
    "squares = [x ** 2 for x in nums]\n",
    "print(squares) # Prints \"[0, 1, 4, 9, 16]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0, 1, 2, 3, 4]\n",
    "even_squares = [x ** 2 for x in nums if x % 2 == 0]\n",
    "print(even_squares) # Prints \"[0, 4, 16]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'AI': 'Artificial Intelligence', 'DL': 'Deep Learning', 'ML': 'Machine Learning'}\n",
    "print(d['AI']) # Get an entry from a dictionary; prints \"Artificial Intelligence\"\n",
    "print('AI' in d) # Check if a dictionary has a given key; prints \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['NN'] = 'Neural Network' # Set an entry in a dictionary\n",
    "print(d['NN']) # Prints \"Neural Network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d[RNN]) # KeyError: 'RNN' not a key of d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d.get('RNN', 'Not Found')) # Get an element with a default; prints \"Not Found\"\n",
    "print(d.get('AI', 'Not Found')) # Get an element with a default; prints \"Artificial Intelligence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d['AI'] # Remove an element from a dictionary\n",
    "print(d.get('AI', 'Not Found')) # \"AI\" is no longer a key; prints \"Not Found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'AI': 'Artificial Intelligence', 'DL': 'Deep Learning', 'ML': 'Machine Learning'}\n",
    "for abbreviation, concept in d.items():\n",
    "    print('%s stands for %s' % (abbreviation, concept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0, 1, 2, 3, 4]\n",
    "even_num_to_square = {x: x ** 2 for x in nums if x % 2 == 0}\n",
    "print(even_num_to_square) # Prints \"{0: 0, 2: 4, 4: 16}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_concepts = {'AI', 'Deep Learning', 'Machine Learning', 'Neural Network'}\n",
    "print('AI' in AI_concepts) # Check if an element is in a set; prints \"True\"\n",
    "print('RNN' in AI_concepts) # prints \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_concepts.add('Recurrent Neural Network') # Add an element to a set\n",
    "print('RNN' in AI_concepts) # Prints \"True\"\n",
    "print(len(AI_concepts)) # Number of elements in a set; prints \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_concepts.add('AI') # Adding an element that is already in the set does nothing\n",
    "print(len(AI_concepts)) # Prints \"5\"\n",
    "AI_concepts.remove('AI') # Remove an element from a set\n",
    "print(len(AI_concepts)) # Prints \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_concepts = {'AI', 'Deep Learning', 'Machine Learning', 'Neural Network'}\n",
    "for i, concept in enumerate(AI_concepts):\n",
    "    print('#%d: %s' % (i + 1, concept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "print(nums = {int(sqrt(x)) for x in range(30)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {(x, x + 1): x for x in range(10)} # Create a dictionary with tuple keys\n",
    "t = (5, 6) # Create a tuple\n",
    "print(type(t)) # Prints \"<class 'tuple'>\"\n",
    "print(d[t]) # Prints \"5\"\n",
    "print(d[(1, 2)]) # Prints \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0] = 1 # Tuples are immutable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(x):\n",
    "    if x > 0:\n",
    "        return 'positive'\n",
    "    elif x < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'zero'\n",
    "\n",
    "for x in [-1, 0, 1]:\n",
    "    print(sign(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello(name, loud=False):\n",
    "    if loud:\n",
    "        print('HELLO, %s!' % name.upper())\n",
    "    else:\n",
    "        print('Hello, %s' % name)\n",
    "\n",
    "hello('Bob') # Prints \"Hello, Bob\"\n",
    "hello('Fred', loud=True) # Prints \"HELLO, FRED!\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Greeter(object):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, name):\n",
    "        self.name = name # Create an instance variable\n",
    "\n",
    "    # Instance method\n",
    "    def greet(self, loud=False):\n",
    "        if loud:\n",
    "            print('HELLO, %s!' % self.name.upper())\n",
    "        else:\n",
    "            print('Hello, %s' % self.name)\n",
    "\n",
    "g = Greeter('Fred') # Construct an instance of the Greeter class\n",
    "g.greet() # Call an instance method; prints \"Hello, Fred\"\n",
    "g.greet(loud=True) # Call an instance method; prints \"HELLO, FRED!\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Numpy基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3]) # Create an array\n",
    "print(type(a), a.shape, a[0], a[1], a[2])\n",
    "a[0] = 5 # Change an element of the array\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1,2,3],[4,5,6]]) # Create another array\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b.shape)\n",
    "print(b[0, 0], b[0, 1], b[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,2)) # Create an array of all zeros\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.ones((1,2)) # Create an array of all ones\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.full((2,2), 7) # Create a constant array\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.eye(2) # Create a 2x2 identity matrix\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.random.random((2,2)) # Create an array filled with random values\n",
    "print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Array索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "\n",
    "\n",
    "b = a[:2, 1:3]\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[0, 1]) # Prints \"2\"\n",
    "b[0, 0] = 77 # b[0, 0] is the same piece of data as a[0, 1]\n",
    "print(a[0, 1]) # Prints \"77\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_r1 = a[1, :] # Rank 1 view of the second row of a\n",
    "row_r2 = a[1:2, :] # Rank 2 view of the second row of a\n",
    "row_r3 = a[[1], :] # Rank 2 view of the second row of a\n",
    "print(row_r1, row_r1.shape) # Prints \"[5 6 7 8] (4,)\"\n",
    "print(row_r2, row_r2.shape) # Prints \"[[5 6 7 8]] (1, 4)\"\n",
    "print(row_r3, row_r3.shape) # Prints \"[[5 6 7 8]] (1, 4)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_r1 = a[:, 1]\n",
    "col_r2 = a[:, 1:2]\n",
    "print(col_r1, col_r1.shape) # Prints \"[ 2  6 10] (3,)\"\n",
    "print(col_r2, col_r2.shape) # Prints \"[[ 2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用整数索引访问数组中的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2], [3, 4], [5, 6]])\n",
    "print(a[[0, 1, 2], [0, 1, 0]]) # Prints \"[1 4 5]\"\n",
    "\n",
    "print(np.array([a[0, 0], a[1, 1], a[2, 0]])) # Prints \"[1 4 5]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[[0, 0], [1, 1]]) # Prints \"[2 2]\"\n",
    "print(np.array([a[0, 1], a[0, 1]])) # Prints \"[2 2]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用整数索引或转换来自另一个数组的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])\n",
    "print(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([0, 2, 0, 1])\n",
    "print(a[np.arange(4), b]) # Prints \"[ 1  6  7 11]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[np.arange(4), b] += 10\n",
    "print(a) # Prints \"array([[11,  2,  3],"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "布尔值索引元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2], [3, 4], [5, 6]])\n",
    "bool_idx = (a > 2) # Find the elements of a that are bigger than 2;\n",
    "\n",
    "print(bool_idx) # Prints \"[[False False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[bool_idx]) # Prints \"[3 4 5 6]\"\n",
    "print(a[a > 2]) # Prints \"[3 4 5 6]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2]) # Let numpy choose the datatype\n",
    "b = np.array([1.0, 2.0]) # Let numpy choose the datatype\n",
    "c = np.array([1, 2], dtype=np.int64) # Force a particular datatype\n",
    "\n",
    "print(a.dtype, b.dtype, c.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数组运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]], dtype=np.float64)\n",
    "b = np.array([[5,6],[7,8]], dtype=np.float64)\n",
    "\n",
    "print(a + b)\n",
    "print(np.add(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a - b)\n",
    "print(np.subtract(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a * b)\n",
    "print(np.multiply(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a / b)\n",
    "print(np.divide(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[5,6],[7,8]])\n",
    "\n",
    "x = np.array([9,10])\n",
    "y = np.array([11, 12])\n",
    "\n",
    "print(x.dot(y))\n",
    "print(np.dot(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x @ y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.dot(x))\n",
    "print(np.dot(a, x))\n",
    "print(a @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.dot(b))\n",
    "print(np.dot(a, b))\n",
    "print(a @ b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy函数运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "\n",
    "print(np.sum(x)) # Compute sum of all elements; prints \"10\"\n",
    "print(np.sum(x, axis=0)) # Compute sum of each column; prints \"[4 6]\"\n",
    "print(np.sum(x, axis=1)) # Compute sum of each row; prints \"[3 7]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(\"transpose\\n\", x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[1,2,3]])\n",
    "print(y)\n",
    "print(\"transpose\\n\", y.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 广播\n",
    "广播可以让我们处理不同形状的数组，对他们进行运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "v = np.array([1, 0, 1])\n",
    "y = np.empty_like(x) # Create an empty matrix with the same shape as x\n",
    "\n",
    "for i in range(4):\n",
    "    y[i, :] = x[i, :] + v\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果x非常大的话，这样操作就会十分耗时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = np.tile(v, (4, 1)) # Stack 4 copies of v on top of each other\n",
    "print(vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + vv # Add x and vv elementwise\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "v = np.array([1, 0, 1])\n",
    "y = x + v # Add v to each row of x using broadcasting\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=x+v 尽管x的形状是(4,3)，v的形状是(3,)，但是v会被广播到x的每一行，因此输出的形状是(4,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1,2,3]) # v has shape (3,)\n",
    "w = np.array([4,5]) # w has shape (2,)\n",
    "print(np.reshape(v, (3, 1)) * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "print(x + v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((x.T + w).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x + np.reshape(w, (2, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x * 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Matplotlib基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 3 * np.pi, 0.1)\n",
    "y = np.sin(x)\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sin = np.sin(x)\n",
    "y_cos = np.cos(x)\n",
    "\n",
    "plt.plot(x, y_sin)\n",
    "plt.plot(x, y_cos)\n",
    "plt.xlabel('x axis label')\n",
    "plt.ylabel('y axis label')\n",
    "plt.title('Sine and Cosine')\n",
    "plt.legend(['Sine', 'Cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 3 * np.pi, 0.1)\n",
    "y_sin = np.sin(x)\n",
    "y_cos = np.cos(x)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "plt.plot(x, y_sin)\n",
    "plt.title('Sine')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x, y_cos)\n",
    "plt.title('Cosine')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pytorch基础\n",
    "- Pytorch基础数据类型：张量、变量、自动求导\n",
    "- 神经网络模块\n",
    "- 神经网络训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Import pprint, module we use for making our print statements prettier\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pytorch基础数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = [\n",
    "  [1, 2, 3],\n",
    "  [4, 5, 6],\n",
    "]\n",
    "print(list_of_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a tensor\n",
    "data = torch.tensor([\n",
    "                     [0, 1],    \n",
    "                     [2, 3],\n",
    "                     [4, 5]\n",
    "                    ])\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每一个张量都有一种数据类型，最主要的两种是torch.float32和torch.int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a tensor with an explicit data type\n",
    "# Notice the dots after the numbers, which specify that they're floats\n",
    "data = torch.tensor([\n",
    "                     [0, 1],    \n",
    "                     [2, 3],\n",
    "                     [4, 5]\n",
    "                    ], dtype=torch.float32)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a tensor with an explicit data type\n",
    "# Notice the dots after the numbers, which specify that they're floats\n",
    "data = torch.tensor([\n",
    "                     [0.11111111, 1],    \n",
    "                     [2, 3],\n",
    "                     [4, 5]\n",
    "                    ], dtype=torch.float32)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a tensor with an explicit data type\n",
    "# Notice the dots after the numbers, which specify that they're floats\n",
    "data = torch.tensor([\n",
    "                     [0.11111111, 1],    \n",
    "                     [2, 3],\n",
    "                     [4, 5]\n",
    "                    ])\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 常用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros(2, 5)  # a tensor of all zeros\n",
    "print(zeros) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = torch.ones(3, 4)   # a tensor of all ones\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = torch.arange(1, 10) # range from [1, 10) \n",
    "print(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2], [2, 3], [4, 5]])      # (3, 2)\n",
    "b = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])  # (2, 4)  (3, 4)\n",
    "\n",
    "print(\"A is\", a)\n",
    "print(\"B is\", b)\n",
    "print(\"The product is\", a.matmul(b))\n",
    "print(\"The other product is\", a @ b) # +, -, *, @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[1, 2, 3], [4, 5, 6]]) @ v  #(2, 3) @ (3)  -> (2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr_2d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(matr_2d.shape)\n",
    "print(matr_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr_3d = torch.tensor([[[1, 2, 3, 4], [-2, 5, 6, 9]], [[5, 6, 7, 2], [8, 9, 10, 4]], [[-3, 2, 2, 1], [4, 6, 5, 9]]])\n",
    "print(matr_3d)\n",
    "print(matr_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = torch.arange(1, 16)\n",
    "print(\"The shape is currently\", rr.shape)\n",
    "print(\"The contents are currently\", rr)\n",
    "print()\n",
    "rr = rr.view(5, 3)\n",
    "print(\"After reshaping, the shape is currently\", rr.shape)\n",
    "print(\"The contents are currently\", rr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy与tensor的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# numpy.ndarray --> torch.Tensor:\n",
    "arr = np.array([[1, 0, 5]])\n",
    "data = torch.tensor(arr)\n",
    "print(\"This is a torch.tensor\", data)\n",
    "\n",
    "# torch.Tensor --> numpy.ndarray:\n",
    "new_arr = data.numpy()\n",
    "print(\"This is a np.ndarray\", new_arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 并行操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.arange(1, 36, dtype=torch.float32).reshape(5, 7)\n",
    "print(\"Data is:\", data)\n",
    "\n",
    "# We can perform operations like *sum* over each row...\n",
    "print(\"Taking the sum over columns:\")\n",
    "print(data.sum(dim=0))\n",
    "\n",
    "# or over each column.\n",
    "print(\"Taking thep sum over rows:\")\n",
    "print(data.sum(dim=1))\n",
    "\n",
    "# Other operations are available:\n",
    "print(\"Taking the stdev over rows:\")\n",
    "print(data.std(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([[1, 2.2, 9.6], [4, -7.2, 6.3]])\n",
    "\n",
    "row_avg = data.mean(dim=1)\n",
    "col_avg = data.mean(dim=0)\n",
    "\n",
    "print(row_avg.shape)\n",
    "print(row_avg)\n",
    "\n",
    "print(col_avg.shape)\n",
    "print(col_avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an example tensor\n",
    "x = torch.Tensor([\n",
    "                  [[1, 2], [3, 4]],\n",
    "                  [[5, 6], [7, 8]], \n",
    "                  [[9, 10], [11, 12]] \n",
    "                 ])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the 0th element, which is the first row\n",
    "x[0] # Equivalent to x[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = torch.arange(1, 16).view(5, 3)\n",
    "print(matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr[0:3, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr[0:3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr[0:3][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr[0,2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top left element of each element in our tensor\n",
    "x[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print x again to see our tensor\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's access the 0th and 1st elements, each twice\n",
    "i = torch.tensor([0, 0, 1, 1])\n",
    "x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's access the 0th elements of the 1st and 2nd elements\n",
    "i = torch.tensor([1, 2])\n",
    "j = torch.tensor([0])\n",
    "x[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0, 0, 0].item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自动求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an example tensor\n",
    "# requires_grad parameter tells PyTorch to store gradients\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "# Print the gradient if it is calculated\n",
    "# Currently None since x is a scalar\n",
    "pp.pprint(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the gradient of y with respect to x\n",
    "y = x * x * 3 # 3x^2\n",
    "y.backward()\n",
    "pp.pprint(x.grad) # d(y)/d(x) = d(3x^2)/d(x) = 6x = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x * x * 3 # 3x^2\n",
    "z.backward()\n",
    "pp.pprint(x.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性层"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用nn.Linear(H_in, H_out)来创建一个线性层，其中H_in是输入的维度，H_out是输出的维度. 另一种表示方法(N, *, H_in) -> (N, *, H_out)，其中N是batch size，*表示任意数量的附加维度。线性层执行以下操作：y=Ax+b，其中A是权重矩阵，b是偏置向量。如果不需要偏置，则可以设置bias=False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the inputs\n",
    "input = torch.ones(2,3,4)\n",
    "# N* H_in -> N*H_out\n",
    "\n",
    "\n",
    "# Make a linear layers transforming N,*,H_in dimensinal inputs to N,*,H_out\n",
    "# dimensional outputs\n",
    "linear = nn.Linear(4, 2)\n",
    "linear_output = linear(input)\n",
    "linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(linear.parameters()) # Ax + b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 激活函数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "激活函数是神经网络中非常重要的一部分，它们可以将线性层的输出转换为非线性的输出，从而使神经网络具有强大的表达能力。PyTorch中提供了很多常用的激活函数，如ReLU、Sigmoid、Tanh、Softmax等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(linear_output)\n",
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 整合不同的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "input = torch.ones(2,3,4)\n",
    "output = block(input)\n",
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义模块"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了使用PyTorch提供的模块，我们还可以自定义模块。自定义模块需要继承nn.Module类，并实现它的forward函数，forward函数定义了模块的前向传播过程。\n",
    "\n",
    "要自定义模块，第一件事情要做的就是拓展nn.Module类，然后我们使用__init__初始化所需要的参数，然后在forward函数中定义前向传播的过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    # Call to the __init__ function of the super class\n",
    "    super(MultilayerPerceptron, self).__init__()\n",
    "\n",
    "    # Bookkeeping: Saving the initialization parameters\n",
    "    self.input_size = input_size \n",
    "    self.hidden_size = hidden_size \n",
    "\n",
    "    # Defining of our model\n",
    "    # There isn't anything specific about the naming of `self.model`. It could\n",
    "    # be something arbitrary.\n",
    "    self.model = nn.Sequential(\n",
    "        nn.Linear(self.input_size, self.hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(self.hidden_size, self.input_size),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    output = self.model(x)\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以不使用nn.Sequential来定义，而是使用单个的函数来定义不同的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    # Call to the __init__ function of the super class\n",
    "    super(MultilayerPerceptron, self).__init__()\n",
    "\n",
    "    # Bookkeeping: Saving the initialization parameters\n",
    "    self.input_size = input_size \n",
    "    self.hidden_size = hidden_size \n",
    "\n",
    "    # Defining of our layers\n",
    "    self.linear = nn.Linear(self.input_size, self.hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.linear2 = nn.Linear(self.hidden_size, self.input_size)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "  def forward(self, x):\n",
    "    linear = self.linear(x)\n",
    "    relu = self.relu(linear)\n",
    "    linear2 = self.linear2(relu)\n",
    "    output = self.sigmoid(linear2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a sample input\n",
    "input = torch.randn(2, 5)\n",
    "\n",
    "# Create our model\n",
    "model = MultilayerPerceptron(5, 3)\n",
    "\n",
    "# Pass our input through our model\n",
    "model(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用named_parameters()函数可以获取模块中所有参数的名称和值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用backward()函数来计算梯度,但是这还不够，我还需要知道如何来更新参数，这就需要使用优化器了。常见的优化器有SGD、Adam、RMSProp等。当我们初始化优化器之后，我们将模型的参数传递给优化器，然后使用优化器的step()函数来更新参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在有了优化器之后，我们能够定义一种损失函数，然后使用优化器来更新参数，这样就能够训练模型了。常见的损失函数有均方误差、交叉熵等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the y data\n",
    "y = torch.ones(10, 5)\n",
    "\n",
    "# Add some noise to our goal y to generate our x\n",
    "# We want out model to predict our original data, albeit the noise\n",
    "x = y + torch.randn_like(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = MultilayerPerceptron(5, 3)\n",
    "\n",
    "# Define the optimizer\n",
    "adam = optim.Adam(model.parameters(), lr=1e-1)\n",
    "\n",
    "# Define loss using a predefined loss function\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "# Calculate how our model is doing now\n",
    "y_pred = model(x)\n",
    "loss_function(y_pred, y).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epoch, which determines the number of training iterations\n",
    "n_epoch = 10 \n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  # Set the gradients to 0\n",
    "  adam.zero_grad()\n",
    "\n",
    "  # Get the model predictions\n",
    "  y_pred = model(x)\n",
    "\n",
    "  # Get the loss\n",
    "  loss = loss_function(y_pred, y)\n",
    "\n",
    "  # Print stats\n",
    "  print(f\"Epoch {epoch}: traing loss: {loss}\")\n",
    "\n",
    "  # Compute the gradients\n",
    "  loss.backward()\n",
    "\n",
    "  # Take a step to optimize the weights\n",
    "  adam.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how our model performs on the training data\n",
    "y_pred = model(x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data and check how our model performs on it\n",
    "x2 = y + torch.randn_like(y)\n",
    "y_pred = model(x2)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "181ed1b5d5864488d810bb30594c12785cc6adebd93158eb6239d338af232ab3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
